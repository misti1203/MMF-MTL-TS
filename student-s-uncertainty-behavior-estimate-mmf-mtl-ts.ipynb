{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7823529,"sourceType":"datasetVersion","datasetId":4584123},{"sourceId":7823619,"sourceType":"datasetVersion","datasetId":4584186},{"sourceId":7823640,"sourceType":"datasetVersion","datasetId":4584203},{"sourceId":7823647,"sourceType":"datasetVersion","datasetId":4584209},{"sourceId":7823663,"sourceType":"datasetVersion","datasetId":4584223},{"sourceId":7824081,"sourceType":"datasetVersion","datasetId":4584519},{"sourceId":7842409,"sourceType":"datasetVersion","datasetId":4597815},{"sourceId":7842480,"sourceType":"datasetVersion","datasetId":4597866},{"sourceId":7842355,"sourceType":"datasetVersion","datasetId":4597769},{"sourceId":16258,"sourceType":"modelInstanceVersion","modelInstanceId":13556}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Import needed libraries","metadata":{}},{"cell_type":"code","source":"import os\nfrom PIL import Image\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom glob import glob\n#---------------------------------------\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\n#---------------------------------------\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten\nfrom tensorflow.keras.optimizers import Adamax\nfrom tensorflow.keras.metrics import Precision, Recall\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n#---------------------------------------\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-03-14T13:16:29.444384Z","iopub.execute_input":"2024-03-14T13:16:29.444804Z","iopub.status.idle":"2024-03-14T13:16:42.521659Z","shell.execute_reply.started":"2024-03-14T13:16:29.444774Z","shell.execute_reply":"2024-03-14T13:16:42.520775Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-03-14 13:16:32.424494: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-14 13:16:32.424621: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-14 13:16:32.574276: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 2. Preprocessing","metadata":{}},{"cell_type":"markdown","source":"## 2.1 Load data","metadata":{}},{"cell_type":"code","source":"'''class_dict = tr_gen.class_indices\nclasses = list(class_dict.keys())\nimages, labels = next(ts_gen)\n\nplt.figure(figsize=(20, 20))\n\nfor i, (image, label) in enumerate(zip(images, labels)):\n    plt.subplot(4,4, i + 1)\n    plt.imshow(image)\n    class_name = classes[np.argmax(label)]\n    plt.title(class_name, color='k', fontsize=15)\n\nplt.show()'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Building Deep Learning Model","metadata":{}},{"cell_type":"code","source":"img_rows, img_cols = 128, 128\ninput_shape = (img_rows, img_cols, 3)\n\n#n_classes = df['category'].nunique()\nn_classes = 4\nprint('Total number of unique categories:', n_classes)\n\nfrom os import listdir, makedirs\nfrom os.path import isfile, join, basename, splitext, isfile, exists\n\nimport numpy as np\nimport pandas as pd\n\nfrom tqdm import tqdm_notebook\n\nimport tensorflow as tf\nimport keras.backend as K\n\nimport keras\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dropout, Dense, Flatten, BatchNormalization\nfrom keras.layers import DepthwiseConv2D, SeparableConvolution2D, Convolution2D, Conv2D,GRU, LSTM, AlphaDropout, Embedding, ZeroPadding2D,AveragePooling2D, MaxPooling2D, GlobalAveragePooling2D, GlobalMaxPooling2D, Dropout\nfrom keras.layers import Concatenate, Average, Maximum, Bidirectional, TimeDistributed\nfrom keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n#from keras.engine.input_layer import Input\nfrom keras.models import load_model\n#from keras.initializers import LecunNormal\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#pd.set_option('precision', 30)\nnp.set_printoptions(precision = 30)\n\n\n#tf.set_random_seed(1090)\n\nimport pandas as pd\nimport numpy as np\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.image as img\n\nimport cv2\nimport itertools\nimport pathlib\nimport warnings\nfrom PIL import Image\nfrom random import randint\nwarnings.filterwarnings('ignore')\n\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import matthews_corrcoef as MCC\nfrom sklearn.metrics import balanced_accuracy_score as BAS\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n\nfrom tensorflow import keras\nfrom keras import layers\nimport tensorflow as tf\n#import tensorflow_addons as tfa\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\n##from keras.utils.vis_utils import plot_model\nfrom tensorflow.keras import Sequential, Input\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.layers import Conv2D, Flatten\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator as IDG\nfrom tensorflow.keras.layers import SeparableConv2D, BatchNormalization, GlobalAveragePooling2D\n\nfrom distutils.dir_util import copy_tree, remove_tree\n\nimport os\n#print(os.listdir(\"../input/alzheimer-mri-dataset/Dataset\"))\nimport tensorflow as tf\nfrom keras.datasets import mnist\nimport cv2\nimport os\nimport pathlib\nfrom keras.layers import Conv2D, Conv2DTranspose,Concatenate, Dropout, Dense, Reshape, LayerNormalization, LeakyReLU\nfrom keras import layers, models\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.metrics import f1_score, recall_score, precision_score\nprint(\"TensorFlow Version:\", tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2024-03-14T13:16:42.523361Z","iopub.execute_input":"2024-03-14T13:16:42.523891Z","iopub.status.idle":"2024-03-14T13:16:43.085096Z","shell.execute_reply.started":"2024-03-14T13:16:42.523865Z","shell.execute_reply":"2024-03-14T13:16:43.084137Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Total number of unique categories: 4\nTensorFlow Version: 2.15.0\n","output_type":"stream"}]},{"cell_type":"code","source":"## for covid disease datasets: ctscan and cxr\nimport numpy as np\nX_test_covid_ct = np.load('/kaggle/input/for-teacher-2-covid-ct-scan-and-cxr-data/X_test_covid_ct.npy')\nX_test_covid_ct = X_test_covid_ct.astype(np.float32)\n\nX_test_covid_cxr = np.load('/kaggle/input/for-teacher-2-covid-ct-scan-and-cxr-data/X_test_covid_cxr.npy')\nX_test_covid_cxr = X_test_covid_cxr.astype(np.float32)\n\nX_val_covid_ct = np.load('/kaggle/input/for-teacher-2-covid-ct-scan-and-cxr-data/X_val_covid_ct.npy')\nX_val_covid_ct = X_val_covid_ct.astype(np.float32)\n\nX_val_covid_cxr = np.load('/kaggle/input/for-teacher-2-covid-ct-scan-and-cxr-data/X_val_covid_cxr.npy')\nX_val_covid_cxr = X_val_covid_cxr.astype(np.float32)\n\nimages_train_covid_ct = np.load('/kaggle/input/for-teacher-2-covid-ct-scan-and-cxr-data/images_train_covid_ct.npy')\nimages_train_covid_ct = images_train_covid_ct.astype(np.float32)\n\nimages_train_covid_cxr = np.load('/kaggle/input/for-teacher-2-covid-ct-scan-and-cxr-data/images_train_covid_cxr.npy')\nimages_train_covid_cxr = images_train_covid_cxr.astype(np.float32)\n\nlabels_train_covid_ct = np.load('/kaggle/input/for-teacher-2-covid-ct-scan-and-cxr-data/labels_train_covid_ct.npy')\nlabels_train_covid_cxr = np.load('/kaggle/input/for-teacher-2-covid-ct-scan-and-cxr-data/labels_train_covid_cxr.npy')\n\ny_test_covid_ct = np.load('/kaggle/input/for-teacher-2-covid-ct-scan-and-cxr-data/y_test_covid_ct.npy')\ny_test_covid_cxr = np.load('/kaggle/input/for-teacher-2-covid-ct-scan-and-cxr-data/y_test_covid_cxr.npy')\ny_val_covid_ct = np.load('/kaggle/input/for-teacher-2-covid-ct-scan-and-cxr-data/y_val_covid_ct.npy')\ny_val_covid_cxr = np.load('/kaggle/input/for-teacher-2-covid-ct-scan-and-cxr-data/y_val_covid_cxr.npy')\n\n\nprint('X_test_covid_ct:',X_test_covid_ct.shape)\nprint('X_test_covid_cxr:',X_test_covid_cxr.shape)\nprint('X_val_covid_ct:',X_val_covid_ct.shape)\nprint('X_val_covid_cxr:',X_val_covid_cxr.shape)\n\nprint('images_train_covid_ct:',images_train_covid_ct.shape)\nprint('images_train_covid_cxr:',images_train_covid_cxr.shape)\nprint('labels_train_covid_ct:',labels_train_covid_ct.shape)\nprint('labels_train_covid_cxr:',labels_train_covid_cxr.shape)\n\nprint('y_test_covid_ct:',y_test_covid_ct.shape)\nprint('y_test_covid_cxr:',y_test_covid_cxr.shape)\nprint('y_val_covid_ct:',y_val_covid_ct.shape)\nprint('y_val_covid_cxr:',y_val_covid_cxr.shape)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-14T13:16:43.086506Z","iopub.execute_input":"2024-03-14T13:16:43.087029Z","iopub.status.idle":"2024-03-14T13:17:44.398157Z","shell.execute_reply.started":"2024-03-14T13:16:43.087002Z","shell.execute_reply":"2024-03-14T13:17:44.397216Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"X_test_covid_ct: (656, 128, 128, 3)\nX_test_covid_cxr: (656, 128, 128, 3)\nX_val_covid_ct: (655, 128, 128, 3)\nX_val_covid_cxr: (655, 128, 128, 3)\nimages_train_covid_ct: (5712, 128, 128, 3)\nimages_train_covid_cxr: (5712, 128, 128, 3)\nlabels_train_covid_ct: (5712, 2)\nlabels_train_covid_cxr: (5712, 3)\ny_test_covid_ct: (656, 2)\ny_test_covid_cxr: (656, 3)\ny_val_covid_ct: (655, 2)\ny_val_covid_cxr: (655, 3)\n","output_type":"stream"}]},{"cell_type":"code","source":"soft_prob_covid_cxr = np.load('/kaggle/input/teacher-2-soft-predictions/soft_pred_train_covid_cxr.npy')\nsoft_prob_covid_ct = np.load('/kaggle/input/teacher-2-soft-predictions/y_pred_covid_ctscan.npy')\n\nprint('soft_prob_covid_cxr:',soft_prob_covid_cxr.shape)\nprint('soft_prob_covid_ct:',soft_prob_covid_ct.shape)","metadata":{"execution":{"iopub.status.busy":"2024-03-14T13:17:44.400333Z","iopub.execute_input":"2024-03-14T13:17:44.400634Z","iopub.status.idle":"2024-03-14T13:17:44.422655Z","shell.execute_reply.started":"2024-03-14T13:17:44.400608Z","shell.execute_reply":"2024-03-14T13:17:44.421897Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"soft_prob_covid_cxr: (5712, 3)\nsoft_prob_covid_ct: (5712, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"## for brain disease datasets: mri and ctscan\nimport numpy as np\nX_test_brain_mri = np.load('/kaggle/input/teacher-1-brain-mri-ctscan/X_test_mri.npy')\nX_test_brain_mri = X_test_brain_mri.astype(np.float32)\n\nX_test_brain_ct = np.load('/kaggle/input/teacher-1-brain-mri-ctscan/X_test_ct.npy')\nX_test_brain_ct = X_test_brain_ct.astype(np.float32)\n\nX_val_brain_mri = np.load('/kaggle/input/teacher-1-brain-mri-ctscan/X_val_mri.npy')\nX_val_brain_mri = X_val_brain_mri.astype(np.float32)\n\nX_val_brain_ct = np.load('/kaggle/input/teacher-1-brain-mri-ctscan/X_val_ct.npy')\nX_val_brain_ct = X_val_brain_ct.astype(np.float32)\n\nimages_train_brain_mri = np.load('/kaggle/input/teacher-1-brain-mri-ctscan/images_train (1).npy')\nimages_train_brain_mri = images_train_brain_mri.astype(np.float32)\n\nimages_train_brain_ct = np.load('/kaggle/input/teacher-1-brain-mri-ctscan/images_train_ct.npy')\nimages_train_brain_ct = images_train_brain_ct.astype(np.float32)\n\nlabels_train_brain_ct = np.load('/kaggle/input/teacher-1-brain-mri-ctscan/labels_train_ct.npy')\nlabels_train_brain_mri = np.load('/kaggle/input/teacher-1-brain-mri-ctscan/labels_train_mri.npy')\n\ny_test_brain_ct = np.load('/kaggle/input/teacher-1-brain-mri-ctscan/y_test_ct.npy')\ny_test_brain_mri = np.load('/kaggle/input/teacher-1-brain-mri-ctscan/y_test_mri.npy')\ny_val_brain_mri = np.load('/kaggle/input/teacher-1-brain-mri-ctscan/y_val_mri.npy')\ny_val_brain_ct = np.load('/kaggle/input/teacher-1-brain-mri-ctscan/y_val_ct.npy')\n\nsoft_prob_brain_mri = np.load('/kaggle/input/teacher-1-soft-predictions-brain/soft_pred_train_teacher1_brain_mri.npy')\nsoft_prob_brain_ct = np.load('/kaggle/input/teacher-1-soft-predictions-brain/soft_pred_train_teacher1_brain_ctscan.npy')\n\nprint('X_test_brain_mri:',X_test_brain_mri.shape)\nprint('X_test_brain_ct:',X_test_brain_ct.shape)\nprint('X_val_brain_mri:',X_val_brain_mri.shape)\nprint('X_val_brain_ct:',X_val_brain_ct.shape)\n\nprint('images_train_brain_mri:',images_train_brain_mri.shape)\nprint('images_train_brain_ct:',images_train_brain_ct.shape)\nprint('labels_train_brain_mri:',labels_train_brain_mri.shape)\nprint('labels_train_brain_ct:',labels_train_brain_ct.shape)\n\nprint('y_test_brain_mri:',y_test_brain_mri.shape)\nprint('y_test_brain_ct:',y_test_brain_ct.shape)\nprint('y_val_brain_mri:',y_val_brain_mri.shape)\nprint('y_val_brain_ct:',y_val_brain_ct.shape)\n\nprint('soft_prob_brain_mri:',soft_prob_brain_mri.shape)\nprint('soft_prob_brain_ct:',soft_prob_brain_ct.shape)","metadata":{"execution":{"iopub.status.busy":"2024-03-14T13:17:44.423986Z","iopub.execute_input":"2024-03-14T13:17:44.424387Z","iopub.status.idle":"2024-03-14T13:18:43.572858Z","shell.execute_reply.started":"2024-03-14T13:17:44.424354Z","shell.execute_reply":"2024-03-14T13:18:43.571910Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"X_test_brain_mri: (656, 128, 128, 3)\nX_test_brain_ct: (656, 128, 128, 3)\nX_val_brain_mri: (655, 128, 128, 3)\nX_val_brain_ct: (655, 128, 128, 3)\nimages_train_brain_mri: (5712, 128, 128, 3)\nimages_train_brain_ct: (5712, 128, 128, 3)\nlabels_train_brain_mri: (5712, 4)\nlabels_train_brain_ct: (5712, 2)\ny_test_brain_mri: (656, 4)\ny_test_brain_ct: (656, 2)\ny_val_brain_mri: (655, 4)\ny_val_brain_ct: (655, 2)\nsoft_prob_brain_mri: (5712, 4)\nsoft_prob_brain_ct: (5712, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers\n\nclass DeeperGlobalLocalAttentionLayer(layers.Layer):\n    def __init__(self, units, activation='sigmoid', dropout_rate=0.2, use_scale=True, **kwargs):\n        super(DeeperGlobalLocalAttentionLayer, self).__init__(**kwargs)\n        self.units = units\n        self.activation = activation\n        self.dropout_rate = dropout_rate\n        self.use_scale = use_scale\n\n    def build(self, input_shape):\n        _, _, _, channels = input_shape\n        self.global_avg_pooling = layers.GlobalAveragePooling2D()\n        self.global_attention = layers.Dense(units=self.units, activation=self.activation)\n        \n        self.local_conv1 = layers.Conv2D(filters=self.units, kernel_size=(1, 1), activation=self.activation)\n        self.local_conv2 = layers.Conv2D(filters=self.units, kernel_size=(1, 1), activation=self.activation)\n        \n        if self.use_scale:\n            self.global_scale = self.add_weight(shape=(1, 1, 1, 1), initializer='ones', trainable=True, name='global_scale')\n            self.local_scale = self.add_weight(shape=(1, 1, 1, self.units), initializer='ones', trainable=True, name='local_scale')\n        \n        super(DeeperGlobalLocalAttentionLayer, self).build(input_shape)\n\n    def call(self, inputs, training=None):\n        # Deeper Global Attention\n        global_avg = self.global_avg_pooling(inputs)\n        global_attention = self.global_attention(global_avg)\n        global_attention = tf.expand_dims(tf.expand_dims(global_attention, 1), 1)\n\n        # Deeper Local Attention\n        local_attention1 = self.local_conv1(inputs)\n        local_attention1 = tf.reduce_mean(local_attention1, axis=[1, 2], keepdims=True)  # Reduce spatial dimensions\n        local_attention2 = self.local_conv2(local_attention1)\n        local_attention = tf.reduce_mean(local_attention2, axis=[1, 2], keepdims=True)  # Reduce spatial dimensions\n\n        # Scale Global and Local Attention\n        if self.use_scale:\n            global_attention *= self.global_scale\n            local_attention *= self.local_scale\n\n        # Combine Global and Local Attention\n        attention = tf.sigmoid(global_attention + local_attention)\n        return attention\n\n    def get_config(self):\n        config = super(DeeperGlobalLocalAttentionLayer, self).get_config()\n        config.update({'units': self.units, 'activation': self.activation, 'dropout_rate': self.dropout_rate,\n                       'use_scale': self.use_scale})\n        return config\n\nclass DeeperAttentionLayer(layers.Layer):\n    def __init__(self, units=64, use_scale=True, **kwargs):\n        super(DeeperAttentionLayer, self).__init__(**kwargs)\n        self.units = units\n        self.use_scale = use_scale\n\n    def build(self, input_shape):\n        _, H, W, C = input_shape\n        self.alpha = self.add_weight(shape=(1, 1, 1, C), initializer='ones', trainable=True, name='alpha')\n        self.deeper_global_local_attention = DeeperGlobalLocalAttentionLayer(units=self.units, activation='sigmoid', \n                                                                              dropout_rate=0.2,  # You can adjust the dropout rate\n                                                                              use_scale=self.use_scale)\n        super(DeeperAttentionLayer, self).build(input_shape)\n\n    def call(self, inputs, training=None):\n        attention = self.deeper_global_local_attention(inputs, training=training)\n        attention_feature = inputs * attention * self.alpha\n        return attention_feature\n\n    def get_config(self):\n        config = super(DeeperAttentionLayer, self).get_config()\n        config.update({'units': self.units, 'use_scale': self.use_scale})\n        return config\n","metadata":{"execution":{"iopub.status.busy":"2024-03-14T13:18:43.574643Z","iopub.execute_input":"2024-03-14T13:18:43.575041Z","iopub.status.idle":"2024-03-14T13:18:43.594007Z","shell.execute_reply.started":"2024-03-14T13:18:43.575006Z","shell.execute_reply":"2024-03-14T13:18:43.593069Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"'''from tensorflow.keras.models import load_model\n\n# Define custom objects dictionary\ncustom_objects = {\n    'DeeperAttentionLayer': DeeperAttentionLayer,\n    ##'distillation_loss': distillation_loss\n}\nimport shutil\n\n# Source path of the model file (read-only directory)\nsource_path = '/kaggle/input/best-teacher-model-brain/best_teacher1_model_brain.keras'\n\n# Destination path in the writable directory\ndestination_path = '/kaggle/working/best_teacher1_model_brain.keras'\n\n# Copy the model file from the source path to the destination path\nshutil.copyfile(source_path, destination_path)\n\n# Load the model with custom objects\nmodel1 = load_model('/kaggle/working/best_teacher1_model_brain.keras', \n                    custom_objects={'DeeperAttentionLayer':DeeperAttentionLayer})\n\n# Now you can use the loaded model for evaluation or further training\nmodel1.evaluate([images_test, images_test_ct], [labels_test_one_hot, labels_test_ct_one_hot])'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''from tensorflow.keras.models import load_model\n\n# Define custom objects dictionary\ncustom_objects = {\n    'DeeperAttentionLayer': DeeperAttentionLayer,\n    ##'distillation_loss': distillation_loss\n}\nimport shutil\n\n# Source path of the model file (read-only directory)\nsource_path = '/kaggle/input/best-teacher-model-brain/best_teacher1_model_brain.keras'\n\n# Destination path in the writable directory\ndestination_path = '/kaggle/working/best_teacher1_model_brain.keras'\n\n# Copy the model file from the source path to the destination path\nshutil.copyfile(source_path, destination_path)\n\n# Load the model with custom objects\nmodel1 = load_model('/kaggle/working/best_teacher1_model_brain.keras', \n                    custom_objects={'DeeperAttentionLayer':DeeperAttentionLayer})\n\n# Now you can use the loaded model for evaluation or further training\nmodel1.evaluate([images_test, images_test_ct], [labels_test_one_hot, labels_test_ct_one_hot])\n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def residual_GLC_branch(inputs):\n    \n    x = Conv2D(filters=64, kernel_size=(7, 7), strides=(2, 2), padding='same')(inputs)\n    x = DeeperAttentionLayer(units=64, use_scale=True)(x)\n    \n    x = BatchNormalization()(x)\n    x = tf.keras.layers.Activation('relu')(x)\n    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n\n    x = RGSA(x, filters=64)\n    x = DeeperAttentionLayer(units=64, use_scale=True)(x)\n    x = RGSA(x, filters=64)\n    x = DeeperAttentionLayer(units=64, use_scale=True)(x)\n    x = tf.keras.layers.Dropout(0.25)(x, training = True)\n\n    x = RGSA(x, filters=128, strides=(2, 2), use_projection=True)\n    x = DeeperAttentionLayer(units=128, use_scale=True)(x)\n    x = RGSA(x, filters=128)\n    x = DeeperAttentionLayer(units=128, use_scale=True)(x)\n    x = tf.keras.layers.Dropout(0.25)(x, training = True)\n\n    x = RGSA(x, filters=256, strides=(2, 2), use_projection=True)\n    x = DeeperAttentionLayer(units=256, use_scale=True)(x)\n    x = RGSA(x, filters=256)\n    x = DeeperAttentionLayer(units=256, use_scale=True)(x)\n    x = tf.keras.layers.Dropout(0.25)(x, training = True)\n\n    x = RGSA(x, filters=512, strides=(2, 2), use_projection=True)\n    x = DeeperAttentionLayer(units=512, use_scale=True)(x)\n    \n    x = RGSA(x, filters=512)\n    x = DeeperAttentionLayer(units=512, use_scale=True)(x)\n    \n    return x","metadata":{"execution":{"iopub.status.busy":"2024-03-14T13:18:43.595161Z","iopub.execute_input":"2024-03-14T13:18:43.595486Z","iopub.status.idle":"2024-03-14T13:18:43.611003Z","shell.execute_reply.started":"2024-03-14T13:18:43.595462Z","shell.execute_reply":"2024-03-14T13:18:43.610116Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\ntf.keras.mixed_precision.set_global_policy('mixed_float16')\n\nimport tensorflow as tf\nimport numpy as np\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D, BatchNormalization, ReLU, Add\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.losses import KLDivergence\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.applications import DenseNet121, ResNet50V2\nfrom tensorflow.keras.layers import GlobalAveragePooling2D\nimport copy\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D, BatchNormalization, ReLU, Add\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.losses import KLDivergence\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.applications import DenseNet169, MobileNetV2, ResNet50, EfficientNetB0\nfrom tensorflow.keras.layers import GlobalAveragePooling2D\nimport copy\n","metadata":{"execution":{"iopub.status.busy":"2024-03-14T13:18:43.612068Z","iopub.execute_input":"2024-03-14T13:18:43.612454Z","iopub.status.idle":"2024-03-14T13:18:43.632788Z","shell.execute_reply.started":"2024-03-14T13:18:43.612427Z","shell.execute_reply":"2024-03-14T13:18:43.631952Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.losses import KLDivergence, CategoricalCrossentropy\n\n#@tf.keras.utils.register_keras_serializable()\ndef adaptive_knowledge_distillation_loss(y_true, y_pred, temperature=10, alpha=0.5, \n                                         beta=0.1, target_loss_weight=0.5):\n    # Compute hard target loss\n    hard_target_loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)(y_true, y_pred)\n\n    # Compute adaptive temperature\n    adaptive_temperature = temperature * (1 + beta * hard_target_loss)\n\n    # Soften the teacher and student predictions with adaptive temperature\n    y_true_soft_adaptive = tf.nn.softmax(y_true / adaptive_temperature, axis=-1)\n    y_pred_soft_adaptive = tf.nn.softmax(y_pred / adaptive_temperature, axis=-1)\n\n    # Compute cross-entropy loss between softened predictions\n    soft_target_loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)(y_true_soft_adaptive, y_pred_soft_adaptive)\n\n    # Compute KL divergence between softened predictions\n    kl_divergence_loss = tf.keras.losses.KLDivergence()(y_true_soft_adaptive, y_pred_soft_adaptive)\n\n    # Weighted sum of cross-entropy loss and KL divergence to develop soft loss\n    loss = alpha * soft_target_loss + (1 - alpha) * kl_divergence_loss\n\n    # Combine losses based on adaptive temperature to generate AKD loss based on soft and hard loss\n    final_loss = (1 - target_loss_weight) * loss + target_loss_weight * hard_target_loss\n\n    return final_loss","metadata":{"execution":{"iopub.status.busy":"2024-03-14T13:18:43.633876Z","iopub.execute_input":"2024-03-14T13:18:43.634148Z","iopub.status.idle":"2024-03-14T13:18:43.643821Z","shell.execute_reply.started":"2024-03-14T13:18:43.634125Z","shell.execute_reply":"2024-03-14T13:18:43.642985Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.losses import KLDivergence, CategoricalCrossentropy\n\n#@tf.keras.utils.register_keras_serializable()\ndef adaptive_knowledge_distillation_loss1(y_true, y_pred, temperature=20, alpha=0.5, \n                                         beta=0.1, target_loss_weight=0.5):\n    # Compute hard target loss\n    hard_target_loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)(y_true, y_pred)\n\n    # Compute adaptive temperature\n    adaptive_temperature = temperature * (1 + beta * hard_target_loss)\n\n    # Soften the teacher and student predictions with adaptive temperature\n    y_true_soft_adaptive = tf.nn.softmax(y_true / adaptive_temperature, axis=-1)\n    y_pred_soft_adaptive = tf.nn.softmax(y_pred / adaptive_temperature, axis=-1)\n\n    # Compute cross-entropy loss between softened predictions\n    soft_target_loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)(y_true_soft_adaptive, y_pred_soft_adaptive)\n\n    # Compute KL divergence between softened predictions\n    kl_divergence_loss = tf.keras.losses.KLDivergence()(y_true_soft_adaptive, y_pred_soft_adaptive)\n\n    # Weighted sum of cross-entropy loss and KL divergence to develop soft loss\n    loss = alpha * soft_target_loss + (1 - alpha) * kl_divergence_loss\n\n    # Combine losses based on adaptive temperature to generate AKD loss based on soft and hard loss\n    final_loss = (1 - target_loss_weight) * loss + target_loss_weight * hard_target_loss\n\n    return final_loss","metadata":{"execution":{"iopub.status.busy":"2024-03-14T13:29:45.695715Z","iopub.execute_input":"2024-03-14T13:29:45.696654Z","iopub.status.idle":"2024-03-14T13:29:45.704744Z","shell.execute_reply.started":"2024-03-14T13:29:45.696608Z","shell.execute_reply":"2024-03-14T13:29:45.703704Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def RGSA(x, filters, strides=(1, 1), use_projection=False):\n    shortcut = x\n\n    # Define the first convolutional layer of the block\n    \n    x = Conv2D(filters=filters, kernel_size=(3, 3), strides=strides, padding='same', \n               #activation = 'relu'\n\n              )(x)\n    x = DeeperAttentionLayer(units=filters, use_scale=True)(x)\n    x = BatchNormalization()(x)\n    x = tf.keras.layers.Activation('relu')(x)\n\n    # Define the second convolutional layer of the block\n    \n    x = Conv2D(filters=filters, kernel_size=(3, 3), padding='same')(x)\n    x = DeeperAttentionLayer(units=filters, use_scale=True)(x)\n    \n    x = BatchNormalization()(x)\n\n    # If the stride is not (1, 1), the dimensions need to be adjusted\n    if strides != (1, 1) or use_projection:\n        \n        shortcut = Conv2D(filters=filters, kernel_size=(1, 1), strides=strides, padding='same')(shortcut)\n        shortcut = BatchNormalization()(shortcut)\n\n    # Add the shortcut (identity connection)\n    \n    x = tf.keras.layers.add([x, shortcut])\n    \n    x = tf.keras.layers.Activation('relu')(x)\n    return x\n\n#def build_resnet18(input_shape=(128, 128, 3), num_classes=2):\ninput_shape=(128, 128, 3)\ninputs = Input(shape=input_shape)\ninputs2 = Input(shape=input_shape)\ninputs3 = Input(shape=input_shape)\ninputs4 = Input(shape=input_shape)\n\n#input_data = Input(shape=input_shape, name='input_data')\n# Initial convolutional layer\n\nx = residual_GLC_branch(inputs)\nx2 = residual_GLC_branch(inputs2)\nx3 = residual_GLC_branch(inputs3)\nx4 = residual_GLC_branch(inputs4)\n\nprint('x:',x.shape)\nprint('x2:',x2.shape)\nprint('x3:',x3.shape)\nprint('x4:',x4.shape)\n# Global average pooling and fully connected layer\n\ncon = tf.keras.layers.Concatenate(axis=-1)([x, x2])\n\nx = GlobalAveragePooling2D()(con)\n\ncon2 = tf.keras.layers.Concatenate(axis=-1)([x3, x4])\nx3 = GlobalAveragePooling2D()(con2)\n\noutputs1 = Dense(4, activation='softmax')(x)\noutputs2 = Dense(2, activation='sigmoid')(x)\n\noutputs3 = Dense(3, activation='softmax')(x3)\noutputs4 = Dense(2, activation='sigmoid')(x3)\n\n# Create the model\nstudent_model = Model([inputs, inputs2,inputs3, inputs4], [outputs1, outputs2, outputs3, outputs4])\n#return model\nprint(student_model.summary())\n# Instantiate the ResNet-18 model\n#model = build_resnet18()\n\n\n#model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n# Train the model\n#model.fit(images_train, y_train_one_hot, epochs=10, batch_size=32, validation_split=0.2)\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\ndef checkpoint_callback():\n\n    checkpoint_filepath = 'best_student_models1_covid_brain.keras'\n\n    model_checkpoint_callback= ModelCheckpoint(filepath=checkpoint_filepath,\n                           save_weights_only=False,\n                           #frequency='epoch',\n                           monitor='val_loss',\n                           save_best_only=True,\n                           verbose=0)\n\n    return model_checkpoint_callback\n\ndef early_stopping(patience):\n    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience, verbose=1)\n    return es_callback\n\n\n\ncheckpoint_callback = checkpoint_callback()\nearly_stopping = early_stopping(patience=100)\ncallbacks = [checkpoint_callback, early_stopping]\n#model.summary()\n'''def distillation_loss(y_true, y_pred):\n    y_true = tf.dtypes.cast(y_true, tf.float32)\n    y_true = tf.nn.softmax(y_true / temperature, axis=-1)\n    y_pred = tf.nn.softmax(y_pred / temperature, axis=-1)\n    return KLDivergence()(y_true, y_pred)\n'''\n'''adaptive_distillation_loss = AdaptiveKnowledgeDistillationLoss(temperature=10, \n                                                               alpha=0.5, beta=0.1, \n                                                               target_loss_weight=0.5)\n'''\nstudent_model.compile(optimizer='adam', loss=[adaptive_knowledge_distillation_loss,\n                                              adaptive_knowledge_distillation_loss,\n                                             adaptive_knowledge_distillation_loss,\n                                             adaptive_knowledge_distillation_loss], \n                      metrics=['accuracy', 'accuracy', 'accuracy', 'accuracy'])\n\n'''\nprint('X_test_covid_ct:',X_test_covid_ct.shape)\nprint('X_test_covid_cxr:',X_test_covid_cxr.shape)\nprint('X_val_covid_ct:',X_val_covid_ct.shape)\nprint('X_val_covid_cxr:',X_val_covid_cxr.shape)\n\nprint('images_train_covid_ct:',images_train_covid_ct.shape)\nprint('images_train_covid_cxr:',images_train_covid_cxr.shape)\nprint('labels_train_covid_ct:',labels_train_covid_ct.shape)\nprint('labels_train_covid_cxr:',labels_train_covid_cxr.shape)\n\nprint('y_test_covid_ct:',y_test_covid_ct.shape)\nprint('y_test_covid_cxr:',y_test_covid_cxr.shape)\nprint('y_val_covid_ct:',y_val_covid_ct.shape)\nprint('y_val_covid_cxr:',y_val_covid_cxr.shape)\n\nprint('soft_prob_covid_cxr:',soft_prob_covid_cxr.shape)\nprint('soft_prob_covid_ct:',soft_prob_covid_ct.shape)\n\nprint('X_test_brain_mri:',X_test_brain_mri.shape)\nprint('X_test_brain_ct:',X_test_brain_ct.shape)\nprint('X_val_brain_mri:',X_val_brain_mri.shape)\nprint('X_val_brain_ct:',X_val_brain_ct.shape)\n\nprint('images_train_brain_mri:',images_train_brain_mri.shape)\nprint('images_train_brain_ct:',images_train_brain_ct.shape)\nprint('labels_train_brain_mri:',labels_train_brain_mri.shape)\nprint('labels_train_brain_ct:',labels_train_brain_ct.shape)\n\nprint('y_test_brain_mri:',y_test_brain_mri.shape)\nprint('y_test_brain_ct:',y_test_brain_ct.shape)\nprint('y_val_brain_mri:',y_val_brain_mri.shape)\nprint('y_val_brain_ct:',y_val_brain_ct.shape)\n#[X_val_covid_cxr, X_val_covid_ct], [y_val_covid_cxr, y_val_covid_ct]\n\n\nprint('soft_prob_brain_mri:',soft_prob_brain_mri.shape)\nprint('soft_prob_brain_ct:',soft_prob_brain_ct.shape)\n'''\nstudent_model.fit(\n    x = [images_train_brain_mri, images_train_brain_ct, \n         images_train_covid_cxr,  images_train_covid_ct], \n    \n    y=([soft_prob_brain_mri, soft_prob_brain_ct, soft_prob_covid_cxr, soft_prob_covid_ct]),\n    epochs=200,\n    #validation_data=([X_val, X_val_c], [y_val, y_val_c]), \n    callbacks = [callbacks],#batch_size=16,\n    #validation_split = 0.2\n    validation_data = ([X_val_brain_mri, X_val_brain_ct, X_val_covid_cxr, X_val_covid_ct],\n                      [y_val_brain_mri, y_val_brain_ct, y_val_covid_cxr, y_val_covid_ct]), verbose=0\n    \n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"student_model.evaluate([X_test_brain_mri, X_test_brain_ct,X_test_covid_cxr, X_test_covid_ct], \n[y_test_brain_mri,y_test_brain_ct, y_test_covid_cxr, y_test_covid_ct])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"student_model.save('dual_best_student_brain_covid_diseases_1.keras')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = student_model.predict([X_test_brain_mri, X_test_brain_ct,X_test_covid_cxr, X_test_covid_ct]) \n#[y_test_brain_mri,y_test_brain_ct, y_test_covid_cxr, y_test_covid_ct])\n#[X_test_mri, X_test_ct], [y_test_mri, y_test_ct]\ny_pred_binary1 = y_pred[0] >= 0.5\ny_pred_binary_pgd_test1 = np.array(y_pred_binary1, dtype='int32')\n\nprint('y_pred_binary_pgd_test1:', y_pred_binary_pgd_test1.shape)\n\ny_pred_binary2 = y_pred[1] >= 0.5\ny_pred_binary_pgd_test2 = np.array(y_pred_binary2, dtype='int32')\n\nprint('y_pred_binary_pgd_test2:', y_pred_binary_pgd_test2.shape)\n\ny_pred_binary3 = y_pred[2] >= 0.5\ny_pred_binary_pgd_test3 = np.array(y_pred_binary3, dtype='int32')\n\nprint('y_pred_binary_pgd_test3:', y_pred_binary_pgd_test3.shape)\n\ny_pred_binary4 = y_pred[3] >= 0.5\ny_pred_binary_pgd_test4 = np.array(y_pred_binary4, dtype='int32')\n\nprint('y_pred_binary_pgd_test4:', y_pred_binary_pgd_test4.shape)\n\n# Calculate evaluation metrics for the current epsilon\ny_test_categorical1 = y_test_brain_mri\ny_test_categorical2 = y_test_brain_ct\ny_test_categorical4 = y_test_covid_ct\ny_test_categorical3 = y_test_covid_cxr\n\n## Task 1:\nprint('Brain Tumours classification in MRI images:')\naccuracy = accuracy_score(y_pred_binary_pgd_test1, y_test_categorical1) * 100\nprecision = precision_score(y_pred_binary_pgd_test1, y_test_categorical1, average='macro') * 100\nrecall = recall_score(y_pred_binary_pgd_test1, y_test_categorical1, average='macro') * 100\nf1 = f1_score(y_pred_binary_pgd_test1, y_test_categorical1, average='macro') * 100\n#auc = roc_auc_score(y_pred, y_train_categorical, multi_class='ovr') * 100\nprint('accuracy:', accuracy)\nprint('precision:', precision)\nprint('recall:', recall)\nprint('f1:', f1)\n\n## Task 2:\nprint('Brain Stroke classification in CT scan images:')\naccuracy = accuracy_score(y_pred_binary_pgd_test2, y_test_categorical2) * 100\nprecision = precision_score(y_pred_binary_pgd_test2, y_test_categorical2, average='macro') * 100\nrecall = recall_score(y_pred_binary_pgd_test2, y_test_categorical2, average='macro') * 100\nf1 = f1_score(y_pred_binary_pgd_test2, y_test_categorical2, average='macro') * 100\nprint('accuracy:', accuracy)\nprint('precision:', precision)\nprint('recall:', recall)\nprint('f1:', f1)\n\n## Task 3:\nprint('COVID19 classification in CXR images:')\naccuracy = accuracy_score(y_pred_binary_pgd_test3, y_test_categorical3) * 100\nprecision = precision_score(y_pred_binary_pgd_test3, y_test_categorical3, average='macro') * 100\nrecall = recall_score(y_pred_binary_pgd_test3, y_test_categorical3, average='macro') * 100\nf1 = f1_score(y_pred_binary_pgd_test3, y_test_categorical3, average='macro') * 100\n#auc = roc_auc_score(y_pred, y_train_categorical, multi_class='ovr') * 100\nprint('accuracy:', accuracy)\nprint('precision:', precision)\nprint('recall:', recall)\nprint('f1:', f1)\n\n## Task 2:\nprint('COVID19 classification in CT scan images:')\naccuracy = accuracy_score(y_pred_binary_pgd_test4, y_test_categorical4) * 100\nprecision = precision_score(y_pred_binary_pgd_test4, y_test_categorical4, average='macro') * 100\nrecall = recall_score(y_pred_binary_pgd_test4, y_test_categorical4, average='macro') * 100\nf1 = f1_score(y_pred_binary_pgd_test4, y_test_categorical4, average='macro') * 100\nprint('accuracy:', accuracy)\nprint('precision:', precision)\nprint('recall:', recall)\nprint('f1:', f1)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1 = load_model('/kaggle/working/best_student_models1_covid_brain.keras', \n                    custom_objects={'DeeperAttentionLayer':DeeperAttentionLayer,\n                                   #'adaptive_knowledge_distillation_loss1':adaptive_knowledge_distillation_loss1,\n                                   'adaptive_knowledge_distillation_loss':adaptive_knowledge_distillation_loss})\n#[X_test_covid_cxr, X_test_covid_ct], [y_test_covid_cxr, y_test_covid_ct]\n# Now you can use the loaded model for evaluation or further training\nmodel1.evaluate([X_test_brain_mri, X_test_brain_ct,X_test_covid_cxr, X_test_covid_ct], \n[y_test_brain_mri,y_test_brain_ct, y_test_covid_cxr, y_test_covid_ct])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model1.predict([X_test_brain_mri, X_test_brain_ct,X_test_covid_cxr, X_test_covid_ct],\n                       batch_size=32) \n#[y_test_brain_mri,y_test_brain_ct, y_test_covid_cxr, y_test_covid_ct])\n#[X_test_mri, X_test_ct], [y_test_mri, y_test_ct]\ny_pred_binary1 = y_pred[0] >= 0.5\ny_pred_binary_pgd_test1 = np.array(y_pred_binary1, dtype='int32')\n\nprint('y_pred_binary_pgd_test1:', y_pred_binary_pgd_test1.shape)\n\ny_pred_binary2 = y_pred[1] >= 0.5\ny_pred_binary_pgd_test2 = np.array(y_pred_binary2, dtype='int32')\n\nprint('y_pred_binary_pgd_test2:', y_pred_binary_pgd_test2.shape)\n\ny_pred_binary3 = y_pred[2] >= 0.5\ny_pred_binary_pgd_test3 = np.array(y_pred_binary3, dtype='int32')\n\nprint('y_pred_binary_pgd_test3:', y_pred_binary_pgd_test3.shape)\n\ny_pred_binary4 = y_pred[3] >= 0.5\ny_pred_binary_pgd_test4 = np.array(y_pred_binary4, dtype='int32')\n\nprint('y_pred_binary_pgd_test4:', y_pred_binary_pgd_test4.shape)\n\n# Calculate evaluation metrics for the current epsilon\ny_test_categorical1 = y_test_brain_mri\ny_test_categorical2 = y_test_brain_ct\ny_test_categorical4 = y_test_covid_ct\ny_test_categorical3 = y_test_covid_cxr\n\n## Task 1:\nprint('Brain Tumours classification in MRI images:')\naccuracy = accuracy_score(y_pred_binary_pgd_test1, y_test_categorical1) * 100\nprecision = precision_score(y_pred_binary_pgd_test1, y_test_categorical1, average='macro') * 100\nrecall = recall_score(y_pred_binary_pgd_test1, y_test_categorical1, average='macro') * 100\nf1 = f1_score(y_pred_binary_pgd_test1, y_test_categorical1, average='macro') * 100\n#auc = roc_auc_score(y_pred, y_train_categorical, multi_class='ovr') * 100\nprint('accuracy:', accuracy)\nprint('precision:', precision)\nprint('recall:', recall)\nprint('f1:', f1)\n\n## Task 2:\nprint('Brain Stroke classification in CT scan images:')\naccuracy = accuracy_score(y_pred_binary_pgd_test2, y_test_categorical2) * 100\nprecision = precision_score(y_pred_binary_pgd_test2, y_test_categorical2, average='macro') * 100\nrecall = recall_score(y_pred_binary_pgd_test2, y_test_categorical2, average='macro') * 100\nf1 = f1_score(y_pred_binary_pgd_test2, y_test_categorical2, average='macro') * 100\nprint('accuracy:', accuracy)\nprint('precision:', precision)\nprint('recall:', recall)\nprint('f1:', f1)\n\n## Task 3:\nprint('COVID19 classification in CXR images:')\naccuracy = accuracy_score(y_pred_binary_pgd_test3, y_test_categorical3) * 100\nprecision = precision_score(y_pred_binary_pgd_test3, y_test_categorical3, average='macro') * 100\nrecall = recall_score(y_pred_binary_pgd_test3, y_test_categorical3, average='macro') * 100\nf1 = f1_score(y_pred_binary_pgd_test3, y_test_categorical3, average='macro') * 100\n#auc = roc_auc_score(y_pred, y_train_categorical, multi_class='ovr') * 100\nprint('accuracy:', accuracy)\nprint('precision:', precision)\nprint('recall:', recall)\nprint('f1:', f1)\n\n## Task 2:\nprint('COVID19 classification in CT scan images:')\naccuracy = accuracy_score(y_pred_binary_pgd_test4, y_test_categorical4) * 100\nprecision = precision_score(y_pred_binary_pgd_test4, y_test_categorical4, average='macro') * 100\nrecall = recall_score(y_pred_binary_pgd_test4, y_test_categorical4, average='macro') * 100\nf1 = f1_score(y_pred_binary_pgd_test4, y_test_categorical4, average='macro') * 100\nprint('accuracy:', accuracy)\nprint('precision:', precision)\nprint('recall:', recall)\nprint('f1:', f1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def RGSA(x, filters, strides=(1, 1), use_projection=False):\n    shortcut = x\n\n    # Define the first convolutional layer of the block\n    \n    x = Conv2D(filters=filters, kernel_size=(3, 3), strides=strides, padding='same', \n               #activation = 'relu'\n\n              )(x)\n    x = DeeperAttentionLayer(units=filters, use_scale=True)(x)\n    x = BatchNormalization()(x)\n    x = tf.keras.layers.Activation('relu')(x)\n\n    # Define the second convolutional layer of the block\n    \n    x = Conv2D(filters=filters, kernel_size=(3, 3), padding='same')(x)\n    x = DeeperAttentionLayer(units=filters, use_scale=True)(x)\n    \n    x = BatchNormalization()(x)\n\n    # If the stride is not (1, 1), the dimensions need to be adjusted\n    if strides != (1, 1) or use_projection:\n        \n        shortcut = Conv2D(filters=filters, kernel_size=(1, 1), strides=strides, padding='same')(shortcut)\n        shortcut = BatchNormalization()(shortcut)\n\n    # Add the shortcut (identity connection)\n    \n    x = tf.keras.layers.add([x, shortcut])\n    \n    x = tf.keras.layers.Activation('relu')(x)\n    return x\n\n#def build_resnet18(input_shape=(128, 128, 3), num_classes=2):\ndef MMF_MTL_TS(input_shape=(128, 128, 3)):\n\n    inputs = Input(shape=input_shape)\n    inputs2 = Input(shape=input_shape)\n    inputs3 = Input(shape=input_shape)\n    inputs4 = Input(shape=input_shape)\n\n    #input_data = Input(shape=input_shape, name='input_data')\n    # Initial convolutional layer\n\n    x = residual_GLC_branch(inputs)\n    x2 = residual_GLC_branch(inputs2)\n    x3 = residual_GLC_branch(inputs3)\n    x4 = residual_GLC_branch(inputs4)\n\n    print('x:',x.shape)\n    print('x2:',x2.shape)\n    print('x3:',x3.shape)\n    print('x4:',x4.shape)\n    # Global average pooling and fully connected layer\n\n    con = tf.keras.layers.Concatenate(axis=-1)([x, x2])\n\n    x = GlobalAveragePooling2D()(con)\n\n    con2 = tf.keras.layers.Concatenate(axis=-1)([x3, x4])\n    x3 = GlobalAveragePooling2D()(con2)\n\n    outputs1 = Dense(4, activation='softmax')(x)\n    outputs2 = Dense(2, activation='sigmoid')(x)\n\n    outputs3 = Dense(3, activation='softmax')(x3)\n    outputs4 = Dense(2, activation='sigmoid')(x3)\n\n    # Create the model\n    student_model = Model([inputs, inputs2,inputs3, inputs4], [outputs1, outputs2, outputs3, outputs4])\n    return student_model\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Extimate uncertainty behaviour of the student model of MMF-MTL-TS approach ","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.losses import KLDivergence\n\n# Set a random seed for reproducibility\nnp.random.seed(42)\n\ndef create_ensemble(num_models, input_shape=(128, 128, 3)):\n    ensemble_models = []\n    \n    for _ in range(num_models):\n        model = MMF_MTL_TS(input_shape)  # Assuming ResNet18 is defined elsewhere\n        ensemble_models.append(model)\n    \n    return ensemble_models\n\n# Function to perform Monte Carlo Dropout inference\n\n# Example usage\ninput_shape = (128, 128, 3)\nnum_models = 5\ndropout_rate = 0.25\n\nensemble_models = create_ensemble(num_models, input_shape)\n\n# Train each model in the ensemble\nfor i, model in enumerate(ensemble_models):\n    print(\"Training Model\", i)\n    #model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    model.compile(optimizer='adam', loss=[adaptive_knowledge_distillation_loss,\n                                              adaptive_knowledge_distillation_loss,\n                                             adaptive_knowledge_distillation_loss,\n                                             adaptive_knowledge_distillation_loss], \n                      metrics=['accuracy', 'accuracy', 'accuracy', 'accuracy'])\n\n    \n    # Define checkpoint callback for each model\n    checkpoint = ModelCheckpoint(f\"best_student_models1_covid_brain_{i}.keras\", monitor='val_loss', \n                                 verbose=1, save_best_only=True, mode='min')\n    \n    model.fit(x = [images_train_brain_mri, images_train_brain_ct, images_train_covid_cxr,  images_train_covid_ct], \n    y=([soft_prob_brain_mri, soft_prob_brain_ct, soft_prob_covid_cxr, soft_prob_covid_ct]),\n    epochs=200,\n    #validation_data=([X_val, X_val_c], [y_val, y_val_c]), \n    callbacks = [checkpoint],#batch_size=16,\n    #validation_split = 0.2\n    validation_data = ([X_val_brain_mri, X_val_brain_ct, X_val_covid_cxr, X_val_covid_ct],\n                      [y_val_brain_mri, y_val_brain_ct, y_val_covid_cxr, y_val_covid_ct]), verbose=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, model in enumerate(ensemble_models):\n    model.evaluate([X_test_brain_mri, X_test_brain_ct,X_test_covid_cxr, X_test_covid_ct], \n[y_test_brain_mri,y_test_brain_ct, y_test_covid_cxr, y_test_covid_ct])","metadata":{"execution":{"iopub.status.busy":"2024-03-14T13:58:00.431852Z","iopub.execute_input":"2024-03-14T13:58:00.432249Z","iopub.status.idle":"2024-03-14T13:58:14.532805Z","shell.execute_reply.started":"2024-03-14T13:58:00.432200Z","shell.execute_reply":"2024-03-14T13:58:14.531812Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - dense_100_accuracy: 0.9826 - dense_101_accuracy: 0.9912 - dense_102_accuracy: 0.9626 - dense_103_accuracy: 0.9738 - loss: 1.9718\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - dense_100_accuracy: 0.9700 - dense_101_accuracy: 0.9897 - dense_102_accuracy: 0.9683 - dense_103_accuracy: 0.9625 - loss: 1.9798\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - dense_100_accuracy: 0.9852 - dense_101_accuracy: 0.9805 - dense_102_accuracy: 0.9338 - dense_103_accuracy: 0.9640 - loss: 1.9928\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - dense_100_accuracy: 0.9921 - dense_101_accuracy: 0.9882 - dense_102_accuracy: 0.9509 - dense_103_accuracy: 0.9537 - loss: 1.9846\n\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - dense_100_accuracy: 0.9826 - dense_101_accuracy: 0.9912 - dense_102_accuracy: 0.9626 - dense_103_accuracy: 0.9738 - loss: 1.9718\n","output_type":"stream"}]},{"cell_type":"code","source":"'''def monte_carlo_dropout_inference(model, x1, x2, x3, x4, num_samples=3):\n    predictions = np.zeros((num_samples,) + model.predict([x1, x2, x3, x4],\n                                                          verbose = 0).shape)\n    print(len(predictions))\n    \n    for i in range(num_samples):\n        print(i)\n        predictions[i, :] = model.predict([x1, x2, x3, x4], verbose = 0)\n\n    return predictions\n'''\n\ndef monte_carlo_dropout_inference(model, x1, x2, x3, x4, num_samples=30):\n    predictions_shape = model.predict([x1, x2, x3, x4], verbose=0)[0].shape\n    predictions = np.zeros((num_samples,) + predictions_shape)\n    \n    for i in range(num_samples):\n        predictions[i, :] = model.predict([x1, x2, x3, x4], verbose=0)[0]\n\n    return predictions\n# Perform Monte Carlo Dropout inference for each model in the ensemble\nensemble_predictions = []\nfor model in ensemble_models:\n    predictions = monte_carlo_dropout_inference(model, X_test_brain_mri, \n                                                        X_test_brain_ct,X_test_covid_cxr, X_test_covid_ct)\n    ensemble_predictions.append(predictions)\n\n#print('ensemble_predictions:', ensemble_predictions.shape)\n# Take the mean or other aggregation method across the ensemble predictions\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-14T14:43:28.427142Z","iopub.execute_input":"2024-03-14T14:43:28.428040Z","iopub.status.idle":"2024-03-14T14:49:48.291031Z","shell.execute_reply.started":"2024-03-14T14:43:28.428006Z","shell.execute_reply":"2024-03-14T14:49:48.290099Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"final_prediction_model1 = np.mean(ensemble_predictions[0], axis=0)\n\n# Use the final_prediction for further analysis or decision making\nprint(\"final_prediction_model1:\", final_prediction_model1.shape)","metadata":{"execution":{"iopub.status.busy":"2024-03-14T14:50:35.184286Z","iopub.execute_input":"2024-03-14T14:50:35.184931Z","iopub.status.idle":"2024-03-14T14:50:35.190700Z","shell.execute_reply.started":"2024-03-14T14:50:35.184898Z","shell.execute_reply":"2024-03-14T14:50:35.189619Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"final_prediction_model1: (656, 4)\n","output_type":"stream"}]},{"cell_type":"code","source":"'''def monte_carlo_dropout_inference(model, x1, x2, x3, x4, num_samples=3):\n    predictions = np.zeros((num_samples,) + model.predict([x1, x2, x3, x4],\n                                                          verbose = 0).shape)\n    print(len(predictions))\n    \n    for i in range(num_samples):\n        print(i)\n        predictions[i, :] = model.predict([x1, x2, x3, x4], verbose = 0)\n\n    return predictions\n'''\n\ndef monte_carlo_dropout_inference(model, x1, x2, x3, x4, num_samples=30):\n    predictions_shape = model.predict([x1, x2, x3, x4], verbose=0)[1].shape\n    predictions = np.zeros((num_samples,) + predictions_shape)\n    \n    for i in range(num_samples):\n        predictions[i, :] = model.predict([x1, x2, x3, x4], verbose=0)[1]\n\n    return predictions\n# Perform Monte Carlo Dropout inference for each model in the ensemble\nensemble_predictions = []\nfor model in ensemble_models:\n    predictions = monte_carlo_dropout_inference(model, X_test_brain_mri, \n                                                        X_test_brain_ct,X_test_covid_cxr, X_test_covid_ct)\n    ensemble_predictions.append(predictions)\n\n#print('ensemble_predictions:', ensemble_predictions.shape)\n# Take the mean or other aggregation method across the ensemble predictions\n","metadata":{"execution":{"iopub.status.busy":"2024-03-14T14:18:22.191678Z","iopub.execute_input":"2024-03-14T14:18:22.192490Z","iopub.status.idle":"2024-03-14T14:24:40.208958Z","shell.execute_reply.started":"2024-03-14T14:18:22.192450Z","shell.execute_reply":"2024-03-14T14:24:40.208047Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"final_prediction_model2 = np.mean(ensemble_predictions[0], axis=0)\n\n# Use the final_prediction for further analysis or decision making\nprint(\"final_prediction_model2:\", final_prediction_model2.shape)","metadata":{"execution":{"iopub.status.busy":"2024-03-14T14:25:12.508704Z","iopub.execute_input":"2024-03-14T14:25:12.509710Z","iopub.status.idle":"2024-03-14T14:25:12.515259Z","shell.execute_reply.started":"2024-03-14T14:25:12.509674Z","shell.execute_reply":"2024-03-14T14:25:12.514282Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"final_prediction_model2: (656, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"'''def monte_carlo_dropout_inference(model, x1, x2, x3, x4, num_samples=3):\n    predictions = np.zeros((num_samples,) + model.predict([x1, x2, x3, x4],\n                                                          verbose = 0).shape)\n    print(len(predictions))\n    \n    for i in range(num_samples):\n        print(i)\n        predictions[i, :] = model.predict([x1, x2, x3, x4], verbose = 0)\n\n    return predictions\n'''\n\ndef monte_carlo_dropout_inference(model, x1, x2, x3, x4, num_samples=30):\n    predictions_shape = model.predict([x1, x2, x3, x4], verbose=0)[2].shape\n    predictions = np.zeros((num_samples,) + predictions_shape)\n    \n    for i in range(num_samples):\n        predictions[i, :] = model.predict([x1, x2, x3, x4], verbose=0)[2]\n\n    return predictions\n# Perform Monte Carlo Dropout inference for each model in the ensemble\nensemble_predictions = []\nfor model in ensemble_models:\n    predictions = monte_carlo_dropout_inference(model, X_test_brain_mri, \n                                                        X_test_brain_ct,X_test_covid_cxr, X_test_covid_ct)\n    ensemble_predictions.append(predictions)\n\n#print('ensemble_predictions:', ensemble_predictions.shape)\n# Take the mean or other aggregation method across the ensemble predictions\n","metadata":{"execution":{"iopub.status.busy":"2024-03-14T14:26:31.001415Z","iopub.execute_input":"2024-03-14T14:26:31.002197Z","iopub.status.idle":"2024-03-14T14:27:19.607138Z","shell.execute_reply.started":"2024-03-14T14:26:31.002164Z","shell.execute_reply":"2024-03-14T14:27:19.606256Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"final_prediction_model3 = np.mean(ensemble_predictions[0], axis=0)\n\n# Use the final_prediction for further analysis or decision making\nprint(\"final_prediction_model3:\", final_prediction_model3.shape)","metadata":{"execution":{"iopub.status.busy":"2024-03-14T14:33:24.065332Z","iopub.execute_input":"2024-03-14T14:33:24.066111Z","iopub.status.idle":"2024-03-14T14:33:24.071469Z","shell.execute_reply.started":"2024-03-14T14:33:24.066075Z","shell.execute_reply":"2024-03-14T14:33:24.070580Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"final_prediction_model3: (656, 3)\n","output_type":"stream"}]},{"cell_type":"code","source":"'''def monte_carlo_dropout_inference(model, x1, x2, x3, x4, num_samples=3):\n    predictions = np.zeros((num_samples,) + model.predict([x1, x2, x3, x4],\n                                                          verbose = 0).shape)\n    print(len(predictions))\n    \n    for i in range(num_samples):\n        print(i)\n        predictions[i, :] = model.predict([x1, x2, x3, x4], verbose = 0)\n\n    return predictions\n'''\n\ndef monte_carlo_dropout_inference(model, x1, x2, x3, x4, num_samples=30):\n    predictions_shape = model.predict([x1, x2, x3, x4], verbose=0)[3].shape\n    predictions = np.zeros((num_samples,) + predictions_shape)\n    \n    for i in range(num_samples):\n        predictions[i, :] = model.predict([x1, x2, x3, x4], verbose=0)[3]\n\n    return predictions\n# Perform Monte Carlo Dropout inference for each model in the ensemble\nensemble_predictions = []\nfor model in ensemble_models:\n    predictions = monte_carlo_dropout_inference(model, X_test_brain_mri, \n                                                        X_test_brain_ct,X_test_covid_cxr, X_test_covid_ct)\n    ensemble_predictions.append(predictions)\n\n#print('ensemble_predictions:', ensemble_predictions.shape)\n# Take the mean or other aggregation method across the ensemble predictions\n","metadata":{"execution":{"iopub.status.busy":"2024-03-14T14:33:57.716940Z","iopub.execute_input":"2024-03-14T14:33:57.717332Z","iopub.status.idle":"2024-03-14T14:34:46.629162Z","shell.execute_reply.started":"2024-03-14T14:33:57.717301Z","shell.execute_reply":"2024-03-14T14:34:46.628112Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"final_prediction_model4 = np.mean(ensemble_predictions[0], axis=0)\n\n# Use the final_prediction for further analysis or decision making\nprint(\"final_prediction_model4:\", final_prediction_model4.shape)","metadata":{"execution":{"iopub.status.busy":"2024-03-14T14:35:54.325453Z","iopub.execute_input":"2024-03-14T14:35:54.325850Z","iopub.status.idle":"2024-03-14T14:35:54.332098Z","shell.execute_reply.started":"2024-03-14T14:35:54.325819Z","shell.execute_reply":"2024-03-14T14:35:54.331070Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"final_prediction_model4: (656, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"y_pred_binary_pgd_test1 = np.argmax(final_prediction_model1, axis=1)\ny_pred_binary_pgd_test2 = np.argmax(final_prediction_model2, axis=1)\ny_pred_binary_pgd_test3 = np.argmax(final_prediction_model3, axis=1)\ny_pred_binary_pgd_test4 = np.argmax(final_prediction_model4, axis=1)\n\ny_test_categorical1 = y_test_brain_mri\ny_test_categorical2 = y_test_brain_ct\ny_test_categorical4 = y_test_covid_ct\ny_test_categorical3 = y_test_covid_cxr\n\ny_test_categorical1 = np.argmax(y_test_categorical1, axis=1)\ny_test_categorical2 = np.argmax(y_test_categorical2, axis=1)\ny_test_categorical3 = np.argmax(y_test_categorical3, axis=1)\ny_test_categorical4 = np.argmax(y_test_categorical4, axis=1)\n\n## Task 1:\nprint('Task 1:')\nprint('Brain Tumours classification in MRI images:')\naccuracy = accuracy_score(y_pred_binary_pgd_test1, y_test_categorical1) * 100\nprecision = precision_score(y_pred_binary_pgd_test1, y_test_categorical1, average='macro') * 100\nrecall = recall_score(y_pred_binary_pgd_test1, y_test_categorical1, average='macro') * 100\nf1 = f1_score(y_pred_binary_pgd_test1, y_test_categorical1, average='macro') * 100\n#auc = roc_auc_score(y_pred, y_train_categorical, multi_class='ovr') * 100\nprint('accuracy:', accuracy)\nprint('precision:', precision)\nprint('recall:', recall)\nprint('f1:', f1)\n\n## Task 2:\nprint('Task 2:')\nprint('Brain Stroke classification in CT scan images:')\naccuracy = accuracy_score(y_pred_binary_pgd_test2, y_test_categorical2) * 100\nprecision = precision_score(y_pred_binary_pgd_test2, y_test_categorical2, average='macro') * 100\nrecall = recall_score(y_pred_binary_pgd_test2, y_test_categorical2, average='macro') * 100\nf1 = f1_score(y_pred_binary_pgd_test2, y_test_categorical2, average='macro') * 100\nprint('accuracy:', accuracy)\nprint('precision:', precision)\nprint('recall:', recall)\nprint('f1:', f1)\n\n## Task 3:\nprint('Task 3:')\nprint('COVID19 classification in CXR images:')\naccuracy = accuracy_score(y_pred_binary_pgd_test3, y_test_categorical3) * 100\nprecision = precision_score(y_pred_binary_pgd_test3, y_test_categorical3, average='macro') * 100\nrecall = recall_score(y_pred_binary_pgd_test3, y_test_categorical3, average='macro') * 100\nf1 = f1_score(y_pred_binary_pgd_test3, y_test_categorical3, average='macro') * 100\n#auc = roc_auc_score(y_pred, y_train_categorical, multi_class='ovr') * 100\nprint('accuracy:', accuracy)\nprint('precision:', precision)\nprint('recall:', recall)\nprint('f1:', f1)\n\n## Task 4:\nprint('Task 4:')\nprint('COVID19 classification in CT scan images:')\naccuracy = accuracy_score(y_pred_binary_pgd_test4, y_test_categorical4) * 100\nprecision = precision_score(y_pred_binary_pgd_test4, y_test_categorical4, average='macro') * 100\nrecall = recall_score(y_pred_binary_pgd_test4, y_test_categorical4, average='macro') * 100\nf1 = f1_score(y_pred_binary_pgd_test4, y_test_categorical4, average='macro') * 100\nprint('accuracy:', accuracy)\nprint('precision:', precision)\nprint('recall:', recall)\nprint('f1:', f1)","metadata":{"execution":{"iopub.status.busy":"2024-03-14T14:56:49.014656Z","iopub.execute_input":"2024-03-14T14:56:49.015064Z","iopub.status.idle":"2024-03-14T14:56:49.068397Z","shell.execute_reply.started":"2024-03-14T14:56:49.015031Z","shell.execute_reply":"2024-03-14T14:56:49.067415Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"Task 1:\nBrain Tumours classification in MRI images:\naccuracy: 98.17073170731707\nprecision: 98.1291377177739\nrecall: 98.18835798809864\nf1: 98.14721364807681\nTask 2:\nBrain Stroke classification in CT scan images:\naccuracy: 98.9329268292683\nprecision: 98.74683744465528\nrecall: 98.98356422861116\nf1: 98.86271042457656\nTask 3:\nCOVID19 classification in CXR images:\naccuracy: 96.64634146341463\nprecision: 96.87642498860009\nrecall: 96.64772276227386\nf1: 96.71197647941834\nTask 4:\nCOVID19 classification in CT scan images:\naccuracy: 97.40853658536585\nprecision: 97.28463109594023\nrecall: 97.57882882882882\nf1: 97.39277823886286\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}